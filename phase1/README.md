# Phase 1 — Dataset Registration & On‑Chain Verification (Sepolia)

This phase delivers a reproducible prototype for **registering dataset Merkle roots on-chain** and **verifying file inclusion proofs** against those on-chain roots.

It contains:
- `register.html` — MetaMask dapp to upload metadata to IPFS and call `registerDataset(datasetId, merkleRoot, metadataCID)`.
- `viewer.html` — Read‑only viewer to list `DatasetRegistered`/`ModelRegistered` events and verify a proof (`verifyFileHash`).
- `ipfs_service.py` — local IPFS proxy (Pinata or Web3.Storage) with simple endpoints the dapp can call.
- `ipfs_config.example.json` — template for IPFS credentials; copy to `ipfs_config.json`.
- Colab / local script (pipeline) to produce tokenized JSONL files, compute leaf hashes, Merkle root, and a **`verify_bundle.json`** for one chosen file.
- Example outputs: `preprocessing_metadata.json` (for IPFS), `verify_bundle.json` (for the Verify UI), `merkle_hashes.txt`, `tokenized_data/`.

> **Network:** Sepolia (testnet).> **Contract:** configurable in both pages; defaults are pre-filled in the inputs.

---

## Repo layout (Phase 1)

```
phase1/
├─ register.html
├─ viewer.html
├─ index.html              # (optional) landing page linking the two
├─ ipfs_service.py
├─ ipfs_config.example.json
├─ preprocessing_metadata.json   # (generated by pipeline; upload via register.html)
├─ verify_bundle.json            # (generated by pipeline; load via viewer.html)
└─ tokenized_data/               # (generated by pipeline; not committed)
```

---

## Prerequisites

- **Python 3.10+**
- **MetaMask** in your browser + a little **Sepolia ETH** (for `registerDataset` gas).
- **FastAPI** + **Uvicorn** for the IPFS proxy:
  ```bash
  pip install fastapi uvicorn requests
  ```
- A Pinata **JWT** _or_ a Web3.Storage **token**.

---

## Configure IPFS proxy

Copy and fill credentials:
```bash
cp ipfs_config.example.json ipfs_config.json
```

**Pinata (JWT)**
```json
{
  "provider": "pinata",
  "pinata": {
    "jwt": "eyJhbGciOi...<your JWT>",
    "gateway": "https://gateway.pinata.cloud/ipfs/"
  }
}
```

**Web3.Storage**
```json
{
  "provider": "web3storage",
  "web3storage": {
    "token": "YOUR_W3S_TOKEN",
    "gateway": "https://w3s.link/ipfs/"
  }
}
```

> Keep `ipfs_config.json` **out of git** (already ignored).

---

## Run the services

### 1) Start IPFS proxy (port 8020)
```bash
uvicorn ipfs_service:app --host 127.0.0.1 --port 8020 --reload
```
Endpoints used by the dapp:
- `POST /ipfs/pin_file` (for `preprocessing_metadata.json`)
- `POST /ipfs/pin_json` (also supported)
- `GET  /version` and `/health` for checks

### 2) Serve the static pages (port 8000)
From the folder containing `register.html` and `viewer.html`:
```bash
python -m http.server 8000
```
Open:
- `http://127.0.0.1:8000/register.html`
- `http://127.0.0.1:8000/viewer.html`

---

## Workflow

### A) Prepare artifacts (Colab/local)
Run the pipeline to produce:
- `tokenized_*.jsonl` files
- **Merkle root** over `keccak(file bytes)` leaves (duplicate last on odd level)
- **`verify_bundle.json`** (for one selected file):  
  ```json
  {
    "datasetId": "0x...",
    "merkleRoot": "0x...",
    "leafHash": "0x...",
    "proof": ["0x...", "0x...", "..."],
    "targetFile": "tokenized_admissions.jsonl",
    "timestamp": "2025-08-10T16:59:41Z"
  }
  ```
- **`preprocessing_metadata.json`** (top-level dataset info incl. `merkle_root`) to be uploaded to IPFS.

### B) Register on-chain (`register.html`)
1. **Connect MetaMask** (Sepolia).  
2. **Upload** `preprocessing_metadata.json` using Step 1 → IPFS proxy. The **CID** auto-fills.
3. Enter **Dataset name** then **Compute datasetId** (or paste a known bytes32).
4. Paste **merkleRoot** from the pipeline.
5. Click **`registerDataset()`** and confirm the tx.

### C) View & verify (`viewer.html`)
1. Fetch `DatasetRegistered` versions for your dataset.
2. Compare local Merkle root with the selected on-chain version.
3. In the **Verify** section, click **Load bundle → fill fields** and select `verify_bundle.json`.
4. Hit **Verify** — you should see **✅ Proof is valid** if the root matches the selected on-chain version.

---

## Troubleshooting

- **Upload to IPFS → “Failed to fetch”**
  - Ensure `uvicorn` proxy is running on **127.0.0.1:8020**.
  - Check **CORS**: `ipfs_service.py` allows `http://127.0.0.1:8000` and `:5500`.
  - Verify `ipfs_config.json` format and credentials match your provider.
  - Try `GET http://127.0.0.1:8020/version` in your browser to confirm the proxy loads.

- **CID opens but shows 404**
  - Some gateways need a minute to pin/provide. Try the same CID on a different gateway (e.g., `https://ipfs.io/ipfs/<cid>`).

- **Verify → “❌ Not included / bad proof”**
  - Make sure the **selected on-chain version** corresponds to the **same merkleRoot** used in the bundle.
  - The tree uses **keccak256( file bytes )** for each JSONL leaf and **concatenates 32B|32B** at each level with **duplicate-last** for odd counts.
  - Any change in file bytes (newline differences, ordering, CSV canonicalization) will change leaf, proof, and root.

- **Gas / Tx columns empty**
  - Infura rate limits can prevent fetching receipts. Increase block range and retry; or re-fetch when rate limit resets.

---

## Security & privacy

- Do **not** commit `ipfs_config.json` or private data.
- This is a testnet prototype; keys and tokens are for development only.

---

## Versioning

Create a dedicated branch and tag for the paper snapshot:
```bash
git checkout -b phase1
git commit -m "Phase 1: dataset registration + verification prototype"
git push -u origin phase1
git tag -a v0.1-phase1 -m "Phase 1 complete"
git push origin v0.1-phase1
```

---

## License

MIT (adjust as needed for your project).
